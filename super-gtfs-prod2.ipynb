{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2a737bb0-fdfc-4227-a75f-0cfc48703932",
      "metadata": {
        "id": "2a737bb0-fdfc-4227-a75f-0cfc48703932"
      },
      "source": [
        "Instalacja potrzebnych pakietów (pominąć, jeżeli już są zainstalowane):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "474d7ab5-2bee-42de-9474-db51ec0cdae6",
      "metadata": {
        "tags": [],
        "id": "474d7ab5-2bee-42de-9474-db51ec0cdae6",
        "outputId": "45a53e35-ecaa-4404-b4ed-b4e48bebeb13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.17.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install geopandas\n",
        "%pip install openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d030fd9e-0c04-4db2-b102-f406eb8f7fa7",
      "metadata": {
        "id": "d030fd9e-0c04-4db2-b102-f406eb8f7fa7"
      },
      "source": [
        "Importy potrzebnych paczek:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bb90d833-299c-48c5-944a-226aa326c923",
      "metadata": {
        "tags": [],
        "id": "bb90d833-299c-48c5-944a-226aa326c923"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import os\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from datetime import datetime\n",
        "from urllib.request import urlretrieve\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f29ff6-1c24-4427-9656-31b7d2382c32",
      "metadata": {
        "id": "12f29ff6-1c24-4427-9656-31b7d2382c32"
      },
      "source": [
        "Pobranie sygnatury czasowej - posłuży nam do identyfikacji wersji wygenerowanego przez nas GTFSu.\n",
        "Ignore warning, żeby nas nie irytowało ;) ale spokojnie to można usunąć."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "43596bf9-da07-4421-938b-63cc0c982fd1",
      "metadata": {
        "id": "43596bf9-da07-4421-938b-63cc0c982fd1"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore')\n",
        "czas = datetime.now().strftime(\"%Y%m%d %H-%M-%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff610ce-1736-42d8-9b64-c1f7f0a3d0fa",
      "metadata": {
        "id": "cff610ce-1736-42d8-9b64-c1f7f0a3d0fa"
      },
      "source": [
        "Pobieranie wykazu GTFS z pliku Excel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b22e5de6-aa69-4dbd-a7f1-c94f445e486f",
      "metadata": {
        "id": "b22e5de6-aa69-4dbd-a7f1-c94f445e486f",
        "outputId": "14a613bc-b727-428c-d657-98211c9edd28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'src'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e7f047e0c826>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnazwa_wykaz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'irmir-wykaz-gtfs-prod'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwykaz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnazwa_wykaz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwykaz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwykaz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwykaz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwykaz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwykaz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src'"
          ]
        }
      ],
      "source": [
        "os.chdir('src')\n",
        "nazwa_wykaz = 'irmir-wykaz-gtfs-prod'\n",
        "wykaz = pd.read_excel(nazwa_wykaz + '.xlsx', sheet_name=None)\n",
        "wykaz = wykaz.get(list(wykaz.keys())[0])\n",
        "wykaz = wykaz.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcff0fd2-c1a9-4970-8528-3ed95f3230a6",
      "metadata": {
        "id": "dcff0fd2-c1a9-4970-8528-3ed95f3230a6"
      },
      "source": [
        "Pobieranie GTFS z internetu bądź kopiowanie istniejących - zgodnie z tym, co było umieszczone w wykazie:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f198ce0-ae1f-49db-9ec1-b918d3e3a087",
      "metadata": {
        "id": "8f198ce0-ae1f-49db-9ec1-b918d3e3a087"
      },
      "outputs": [],
      "source": [
        "os.mkdir(czas)\n",
        "os.chdir(czas)\n",
        "\n",
        "for i in range(0, len(wykaz)):\n",
        "    match wykaz.Typ_zrodla.iloc[i]:\n",
        "        case 'U':\n",
        "            print('Pobieram GTFS dla:', wykaz.Skrot.iloc[i])\n",
        "            urlretrieve(wykaz.Adres.iloc[i], wykaz.Skrot.iloc[i] + '.zip')\n",
        "            with ZipFile(wykaz.Skrot.iloc[i] + \".zip\", 'r') as zObject:\n",
        "                zObject.extractall(wykaz.Skrot.iloc[i])\n",
        "            print('===')\n",
        "        case 'F':\n",
        "            print('Kopiuję istniejący GTFS dla:', wykaz.Skrot.iloc[i])\n",
        "            os.chdir('..')\n",
        "            shutil.copyfile(wykaz.Adres.iloc[i] + '.zip', czas + '/' + wykaz.Skrot.iloc[i] + '.zip')\n",
        "            os.chdir(czas)\n",
        "            with ZipFile(wykaz.Skrot.iloc[i] + \".zip\", 'r') as zObject:\n",
        "                zObject.extractall(wykaz.Skrot.iloc[i])\n",
        "            print('===')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b50bf2-ab0e-496b-91dd-c38a2a420b11",
      "metadata": {
        "id": "f3b50bf2-ab0e-496b-91dd-c38a2a420b11"
      },
      "source": [
        "Tworzenie nowych tabel, do których będą scalane poszczególne GTFSy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "570de01e-1f45-45f2-8b8a-057022df8af3",
      "metadata": {
        "id": "570de01e-1f45-45f2-8b8a-057022df8af3"
      },
      "outputs": [],
      "source": [
        "new_stops = pd.DataFrame(columns=['stop_id', 'stop_name', 'stop_lat', 'stop_lon'])\n",
        "new_routes = pd.DataFrame(columns=['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type'])\n",
        "new_trips = pd.DataFrame(columns=['route_id', 'service_id', 'trip_id', 'trip_headsign'])\n",
        "new_agency = pd.DataFrame(columns=['agency_id', 'agency_name','agency_url','agency_timezone'])\n",
        "new_stop_times = pd.DataFrame(columns=['trip_id','arrival_time','departure_time','stop_id','stop_sequence'])\n",
        "new_calendar_dates = pd.DataFrame(columns=['service_id' ,'date', 'exception_type'])\n",
        "new_calendar = pd.DataFrame(columns=['service_id','monday','tuesday','wednesday','thursday','friday','saturday','sunday','start_date','end_date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a081a4-5aef-479f-a20f-f3faab3e2b1b",
      "metadata": {
        "id": "a8a081a4-5aef-479f-a20f-f3faab3e2b1b"
      },
      "source": [
        "Główna pętla - pobieranie danych ze źródłowych GTFS i scalanie ich do tabel. Dla SKM Warszawa utworzony wyjątek, ponieważ ich GTFSy nie istnieją jako osobny plik, lecz jako element składowy w pliku od ZTM Warszawa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a476bfc-ce88-4b81-b432-6b2e52e09473",
      "metadata": {
        "id": "8a476bfc-ce88-4b81-b432-6b2e52e09473"
      },
      "outputs": [],
      "source": [
        "lst_gtfs = next(os.walk('.'))[1]\n",
        "bool_cal = False\n",
        "bool_caldates = False\n",
        "\n",
        "\n",
        "for el in lst_gtfs:\n",
        "    os.chdir(el)\n",
        "    print('Scalam GTFS dla: ', el)\n",
        "    tmp_stops = pd.read_csv('stops.txt').apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
        "    tmp_stops = tmp_stops[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']]\n",
        "    tmp_routes = pd.read_csv('routes.txt').apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
        "    if 'agency_id' in tmp_routes.columns.tolist():\n",
        "        tmp_routes = tmp_routes[['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type']]\n",
        "    else:\n",
        "        tmp_routes = tmp_routes[['route_id', 'route_short_name', 'route_long_name', 'route_type']]\n",
        "        tmp_routes['agency_id'] = el\n",
        "        tmp_routes = tmp_routes[['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type']]\n",
        "    tmp_trips = pd.read_csv('trips.txt', dtype={\"trip_id\": \"string\"}).apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
        "    tmp_trips = tmp_trips[['route_id', 'service_id', 'trip_id', 'trip_headsign']]\n",
        "    tmp_agency = pd.read_csv('agency.txt').apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
        "    if 'agency_id' in tmp_agency.columns.tolist():\n",
        "        tmp_agency = tmp_agency[['agency_id','agency_name','agency_url','agency_timezone']]\n",
        "        tmp_agency.agency_url = 'https://irmir.pl/'\n",
        "    else:\n",
        "        tmp_agency = tmp_agency[['agency_name','agency_url','agency_timezone']]\n",
        "        tmp_agency['agency_id'] = el\n",
        "        tmp_agency = tmp_agency[['agency_id','agency_name','agency_url','agency_timezone']]\n",
        "        tmp_agency.agency_url = 'https://irmir.pl/'\n",
        "    tmp_stop_times = pd.read_csv('stop_times.txt', dtype={\"trip_id\": \"string\"}).apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
        "    tmp_stop_times = tmp_stop_times[['trip_id','arrival_time','departure_time','stop_id','stop_sequence']]\n",
        "    if (os.path.isfile('calendar_dates.txt')):\n",
        "        bool_caldates = True\n",
        "        tmp_calendar_dates = pd.read_csv('calendar_dates.txt').apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
        "        tmp_calendar_dates = tmp_calendar_dates[['service_id' ,'date', 'exception_type']]\n",
        "    if (os.path.isfile('calendar.txt')):\n",
        "        bool_cal = True\n",
        "        tmp_calendar = pd.read_csv('calendar.txt').apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
        "        tmp_calendar = tmp_calendar[['service_id','monday','tuesday','wednesday','thursday','friday','saturday','sunday','start_date','end_date']]\n",
        "\n",
        "    ### filtrowanie\n",
        "    tmp_routes = tmp_routes[tmp_routes.route_type == 2]\n",
        "    if el=='SKMW':\n",
        "        tmp_routes['coltmp'] = tmp_routes.route_short_name.astype(str).str[0]\n",
        "        tmp_routes = tmp_routes[tmp_routes.coltmp == 'S']\n",
        "        tmp_routes = tmp_routes[['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type']]\n",
        "    tmp_trips = tmp_trips[tmp_trips.route_id.isin(tmp_routes.route_id.tolist())]\n",
        "    tmp_stop_times = tmp_stop_times[tmp_stop_times.trip_id.isin(tmp_trips.trip_id.tolist())]\n",
        "    tmp_stops = tmp_stops[tmp_stops.stop_id.isin(tmp_stop_times.stop_id.tolist())]\n",
        "    tmp_agency = tmp_agency[tmp_agency.agency_id.isin(tmp_routes.agency_id.tolist())]\n",
        "\n",
        "    ### dodawanie skrotu do GTFS\n",
        "    tmp_stops.stop_id = el + tmp_stops.stop_id.astype(str)\n",
        "    tmp_routes.route_id = el + tmp_routes.route_id.astype(str)\n",
        "    tmp_routes.agency_id = el\n",
        "    tmp_trips.route_id = el + tmp_trips.route_id.astype(str)\n",
        "    tmp_trips.service_id = el + tmp_trips.service_id.astype(str)\n",
        "    tmp_trips.trip_id = el + tmp_trips.trip_id.astype(str)\n",
        "    tmp_agency.agency_id = el\n",
        "    tmp_stop_times.trip_id = el + tmp_stop_times.trip_id.astype(str)\n",
        "    tmp_stop_times.stop_id = el + tmp_stop_times.stop_id.astype(str)\n",
        "    if bool_caldates:\n",
        "        tmp_calendar_dates.service_id = el + tmp_calendar_dates.service_id.astype(str)\n",
        "    if bool_cal:\n",
        "        tmp_calendar.service_id = el + tmp_calendar.service_id.astype(str)\n",
        "\n",
        "    ### scalanie z główna tabelą\n",
        "    new_stops = pd.concat([new_stops, tmp_stops])\n",
        "    new_routes = pd.concat([new_routes, tmp_routes])\n",
        "    new_trips = pd.concat([new_trips, tmp_trips])\n",
        "    new_agency = pd.concat([new_agency, tmp_agency])\n",
        "    new_stop_times = pd.concat([new_stop_times, tmp_stop_times])\n",
        "    if bool_caldates:\n",
        "        new_calendar_dates = pd.concat([new_calendar_dates, tmp_calendar_dates])\n",
        "    if bool_cal:\n",
        "        new_calendar = pd.concat([new_calendar, tmp_calendar])\n",
        "\n",
        "    print('=== scalone ===')\n",
        "\n",
        "    bool_cal = False\n",
        "    bool_caldates = False\n",
        "    os.chdir('..')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cbb632e-634a-4a5d-b9fc-74832bcdf97d",
      "metadata": {
        "id": "6cbb632e-634a-4a5d-b9fc-74832bcdf97d"
      },
      "source": [
        "Scalanie przystanków i stacji z różnych GTFSów. Ponieważ w plikach źródłowych nie jest używana jedna, wspólna baza, przystanki zostają scalone w ten sposób, że te leżące w odległości 260m od siebie (bufor 130m - wyznaczone \"doświadczalnie\") są połączone w jeden i jako ich lokalizacja brany jest centroid z połączonych buforów.\n",
        "Na koniec zostaje także zaktualizowana tabela stop_times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ae3c9f-47ec-43a1-85af-80f5790e9ad1",
      "metadata": {
        "id": "88ae3c9f-47ec-43a1-85af-80f5790e9ad1"
      },
      "outputs": [],
      "source": [
        "gdf_stops = gpd.GeoDataFrame(new_stops, geometry=gpd.points_from_xy(new_stops.stop_lon, new_stops.stop_lat), crs=\"EPSG:4326\")\n",
        "gdf_stops.geometry = gdf_stops.geometry.to_crs('EPSG:2180')\n",
        "gdf_stops.geometry = gdf_stops.geometry.buffer(130)\n",
        "\n",
        "gdf_intersects = gdf_stops.sjoin(gdf_stops, how=\"left\", predicate=\"intersects\")\n",
        "gdf_intersects_diss = gdf_intersects.dissolve(\"stop_id_right\",aggfunc=\"min\")\n",
        "gdf_intersects_diss = gdf_intersects_diss.reset_index().dissolve(\"stop_id_left\",aggfunc=\"min\")\n",
        "\n",
        "gdf_intersects_diss['centroid'] = gdf_intersects_diss.centroid\n",
        "\n",
        "gdf_intersects_a = gdf_stops.sjoin(gdf_intersects_diss, how=\"left\", predicate=\"intersects\")\n",
        "gdf_intersects_a['new_stop_id'] = 'n_' + gdf_intersects_a.stop_id_left.astype(str)\n",
        "slownik = pd.DataFrame(gdf_intersects_a[['stop_id', 'new_stop_id']])\n",
        "slownik.drop_duplicates(subset=['stop_id'], inplace=True)\n",
        "gdf_przystanki = gdf_intersects_a[['new_stop_id', 'stop_name_left', 'centroid']]\n",
        "\n",
        "gdf_przystanki.geometry = gdf_przystanki.centroid\n",
        "gdf_przystanki.drop_duplicates(inplace=True)\n",
        "gdf_przystanki.geometry = gdf_przystanki.geometry.to_crs('EPSG:4326')\n",
        "gdf_przystanki['stop_lon'] = gdf_przystanki.geometry.x\n",
        "gdf_przystanki['stop_lat'] = gdf_przystanki.geometry.y\n",
        "df_przystanki = pd.DataFrame(gdf_przystanki)\n",
        "df_przystanki = df_przystanki[['new_stop_id','stop_name_left','stop_lat','stop_lon']]\n",
        "df_przystanki.columns = ['stop_id','stop_name','stop_lat','stop_lon']\n",
        "df_przystanki.stop_name = df_przystanki.stop_name.str.title()\n",
        "df_przystanki_a = df_przystanki.drop_duplicates()\n",
        "\n",
        "new_stop_times = pd.merge(left=new_stop_times, right=slownik, left_on='stop_id', right_on='stop_id', how='left')\n",
        "new_stop_times = new_stop_times[['trip_id', 'arrival_time', 'departure_time', 'new_stop_id', 'stop_sequence']]\n",
        "new_stop_times.columns = ['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d708b13-4edc-4f42-9664-3529ef1dab78",
      "metadata": {
        "id": "7d708b13-4edc-4f42-9664-3529ef1dab78"
      },
      "source": [
        "Czyszczenie i eksport do wspólnego GTFSa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b836c20-2cc4-4808-8c21-6e6cda89a7b0",
      "metadata": {
        "id": "3b836c20-2cc4-4808-8c21-6e6cda89a7b0"
      },
      "outputs": [],
      "source": [
        "for el in lst_gtfs:\n",
        "    shutil.rmtree(el)\n",
        "\n",
        "os.chdir('..')\n",
        "os.chdir('..')\n",
        "os.chdir('exports')\n",
        "\n",
        "os.mkdir('_scalony ' + czas)\n",
        "os.chdir('_scalony ' + czas)\n",
        "\n",
        "new_agency.to_csv('agency.txt', index = False)\n",
        "print('Wygenerowano: agency')\n",
        "new_routes.to_csv('routes.txt', index = False)\n",
        "print('Wygenerowano: routes')\n",
        "new_stop_times.to_csv('stop_times.txt', index = False)\n",
        "print('Wygenerowano: stop_times')\n",
        "new_trips.to_csv('trips.txt', index = False)\n",
        "print('Wygenerowano: trips')\n",
        "df_przystanki.to_csv('stops.txt', index = False)\n",
        "print('Wygenerowano: stops')\n",
        "new_calendar.to_csv('calendar.txt', index = False)\n",
        "print('Wygenerowano: calendar')\n",
        "new_calendar_dates.to_csv('calendar_dates.txt', index = False)\n",
        "print('Wygenerowano: calendar_dates')\n",
        "\n",
        "lista_pl_sklad = os.listdir()\n",
        "\n",
        "with ZipFile(\"_scalony GTFS \" + czas + \".zip\", 'w') as zObject2:\n",
        "    for el in lista_pl_sklad:\n",
        "        zObject2.write(el)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".conda-custom_python:Python",
      "language": "python",
      "name": "conda-env-.conda-custom_python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}